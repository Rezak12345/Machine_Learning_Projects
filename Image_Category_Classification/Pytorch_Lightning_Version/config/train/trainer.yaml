lr: 0.001
batch_size: 32
train_split: 0.7
val_split: 0.2
test_split: 0.1

optimizer:
  _target_: torch.optim.Adam

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min
  patience: 10
  factor: 0.05
  min_lr: 0.000001

optimizer_monitor: val_loss

trainer:
  _target_: pytorch_lightning.Trainer
  min_epochs: 30
  max_epochs: 30
  log_every_n_steps: 40
  